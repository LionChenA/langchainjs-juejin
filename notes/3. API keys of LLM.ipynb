{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "041ac04a-bbb6-4173-b3b5-ac797bd34370",
   "metadata": {},
   "source": [
    "# API 的获取\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ff27bf-38e6-4389-8f41-b13a4d77ea88",
   "metadata": {},
   "source": [
    "在 2025 年的今天，获取所有渠道的 API 都已不再是什么大问题。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2805934-4af2-40c7-8793-caf34c14f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在代码中安全引入 API key 的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142082d3-20aa-4052-bf37-204c48c21ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "766d986c-2acc-4dad-8ca4-73ec6d06ec16",
   "metadata": {},
   "source": [
    "新建 .env 文件用于项目环境下的 API 配置\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768be1fc-04db-4229-9c4b-a872e09e695e",
   "metadata": {},
   "source": [
    "# 如何在 Deno 中导入 npm 包？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957fd9fa-788d-4a98-86cb-8214d34840b0",
   "metadata": {},
   "source": [
    "Deno 现支持三种导入第三方包的方式：jsr、npm 或 https，详见[模块和依赖项](https://docs.deno.com/runtime/fundamentals/modules/)。\n",
    "\n",
    "- jsr(JavaScript Registry)：这是 Deno 官方推荐和维护的包注册表、专门为 Deno 优化，提供更好的类型支持和安全性\n",
    "- npm: (Node Package Manager)：允许直接使用 npm 包、Deno 会自动处理依赖关系和类型定义\n",
    "- https://直接从 URL 导入模块、最原始的 Deno 导入方式、可以直接引用任何托管在网络上的 JavaScript/TypeScript 文件\n",
    "  示例代码如下：\n",
    "\n",
    "```js\n",
    "import { camelCase } from \"jsr:@luca/cases@1.0.0\";\n",
    "import { say } from \"npm:cowsay@1.6.0\";\n",
    "import { pascalCase } from \"https://deno.land/x/case/mod.ts\";\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4831c7-731f-41ea-938c-be4f646db389",
   "metadata": {},
   "source": [
    "由于 LangChain 和 OpenAI SDK 目前还没有在 JSR 上发布，我们可以继续使用 npm: 导入，或者使用 https://esm.sh/ 这样的 ESM CDN。比如`import { OpenAI } from \"https://esm.sh/openai@4.28.4\";`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39594b8b-88f4-4e1b-aa7d-434ee4c4f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { HumanMessage } from \"npm:@langchain/core/messages\"\n",
    "import { ChatOpenAI } from \"npm:@langchain/openai\"\n",
    "import { OpenAI } from \"npm:openai\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f9667-6b9b-4c0d-a156-5ac1960068af",
   "metadata": {},
   "source": [
    "# 获取模型列表\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53682cf5-d222-4346-ad99-ebd7e87a4da4",
   "metadata": {},
   "source": [
    "这里要补充一些前置知识，即 OpenAI 推出的 SDK 已经成为了普适的 LLM API 标准，其 js 版为[openai/openai-node](https://github.com/openai/openai-node)。openai-node 提供了对 LLM 的底层访问能力；而 langchian 则提供了高级抽象和工具链。而获取模型列表就需要这样一种底层访问能力。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501aa4b2-f241-4978-9953-ddb90dfa4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "// 初始化 OpenAI SDK 客户端\n",
    "const openai = new OpenAI({\n",
    "  baseURL: \"https://yunwu.ai/v1\",\n",
    "  apiKey: Deno.env.get(\"OPENAI_API_KEY\"),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e973cb-a441-40ea-b089-7018eec4bf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取模型列表中...\n",
      "可用的模型：\n",
      "- o3-mini\n",
      "- text-embedding-3-small\n",
      "- gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "// 获取可用模型列表\n",
    "console.log(\"获取模型列表中...\")\n",
    "const models = await openai.models.list()\n",
    "console.log(\"可用的模型：\")\n",
    "models.data.forEach((model) => {\n",
    "  console.log(`- ${model.id}`)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938f326a-826e-4d5f-a66c-b7f33cce5c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelsPage {\n",
       "  options: { method: \u001b[32m\"get\"\u001b[39m, path: \u001b[32m\"/models\"\u001b[39m },\n",
       "  response: Response {\n",
       "    body: ReadableStream { locked: \u001b[33mtrue\u001b[39m },\n",
       "    bodyUsed: \u001b[33mtrue\u001b[39m,\n",
       "    headers: Headers {\n",
       "      \u001b[32m\"content-type\"\u001b[39m: \u001b[32m\"application/json; charset=utf-8\"\u001b[39m,\n",
       "      date: \u001b[32m\"Tue, 04 Mar 2025 13:20:31 GMT\"\u001b[39m,\n",
       "      server: \u001b[32m\"nginx\"\u001b[39m,\n",
       "      \u001b[32m\"strict-transport-security\"\u001b[39m: \u001b[32m\"max-age=31536000\"\u001b[39m,\n",
       "      vary: \u001b[32m\"Accept-Encoding\"\u001b[39m,\n",
       "      \u001b[32m\"x-oneapi-request-id\"\u001b[39m: \u001b[32m\"202503042120311273337385vI5G5Rv\"\u001b[39m\n",
       "    },\n",
       "    ok: \u001b[33mtrue\u001b[39m,\n",
       "    redirected: \u001b[33mfalse\u001b[39m,\n",
       "    status: \u001b[33m200\u001b[39m,\n",
       "    statusText: \u001b[32m\"OK\"\u001b[39m,\n",
       "    url: \u001b[32m\"https://yunwu.ai/v1/models\"\u001b[39m\n",
       "  },\n",
       "  body: {\n",
       "    data: [\n",
       "      {\n",
       "        id: \u001b[32m\"o3-mini\"\u001b[39m,\n",
       "        object: \u001b[32m\"model\"\u001b[39m,\n",
       "        created: \u001b[33m1626777600\u001b[39m,\n",
       "        owned_by: \u001b[32m\"openai\"\u001b[39m,\n",
       "        permission: [ \u001b[36m[Object]\u001b[39m ],\n",
       "        root: \u001b[32m\"o3-mini\"\u001b[39m,\n",
       "        parent: \u001b[1mnull\u001b[22m\n",
       "      },\n",
       "      {\n",
       "        id: \u001b[32m\"text-embedding-3-small\"\u001b[39m,\n",
       "        object: \u001b[32m\"model\"\u001b[39m,\n",
       "        created: \u001b[33m1626777600\u001b[39m,\n",
       "        owned_by: \u001b[32m\"openai\"\u001b[39m,\n",
       "        permission: [ \u001b[36m[Object]\u001b[39m ],\n",
       "        root: \u001b[32m\"text-embedding-3-small\"\u001b[39m,\n",
       "        parent: \u001b[1mnull\u001b[22m\n",
       "      },\n",
       "      {\n",
       "        id: \u001b[32m\"gpt-4o-mini\"\u001b[39m,\n",
       "        object: \u001b[32m\"model\"\u001b[39m,\n",
       "        created: \u001b[33m1626777600\u001b[39m,\n",
       "        owned_by: \u001b[32m\"openai\"\u001b[39m,\n",
       "        permission: [ \u001b[36m[Object]\u001b[39m ],\n",
       "        root: \u001b[32m\"gpt-4o-mini\"\u001b[39m,\n",
       "        parent: \u001b[1mnull\u001b[22m\n",
       "      }\n",
       "    ],\n",
       "    success: \u001b[33mtrue\u001b[39m\n",
       "  },\n",
       "  data: [\n",
       "    {\n",
       "      id: \u001b[32m\"o3-mini\"\u001b[39m,\n",
       "      object: \u001b[32m\"model\"\u001b[39m,\n",
       "      created: \u001b[33m1626777600\u001b[39m,\n",
       "      owned_by: \u001b[32m\"openai\"\u001b[39m,\n",
       "      permission: [\n",
       "        {\n",
       "          id: \u001b[32m\"modelperm-LwHkVFn8AcMItP432fKKDIKJ\"\u001b[39m,\n",
       "          object: \u001b[32m\"model_permission\"\u001b[39m,\n",
       "          created: \u001b[33m1626777600\u001b[39m,\n",
       "          allow_create_engine: \u001b[33mtrue\u001b[39m,\n",
       "          allow_sampling: \u001b[33mtrue\u001b[39m,\n",
       "          allow_logprobs: \u001b[33mtrue\u001b[39m,\n",
       "          allow_search_indices: \u001b[33mfalse\u001b[39m,\n",
       "          allow_view: \u001b[33mtrue\u001b[39m,\n",
       "          allow_fine_tuning: \u001b[33mfalse\u001b[39m,\n",
       "          organization: \u001b[32m\"*\"\u001b[39m,\n",
       "          group: \u001b[1mnull\u001b[22m,\n",
       "          is_blocking: \u001b[33mfalse\u001b[39m\n",
       "        }\n",
       "      ],\n",
       "      root: \u001b[32m\"o3-mini\"\u001b[39m,\n",
       "      parent: \u001b[1mnull\u001b[22m\n",
       "    },\n",
       "    {\n",
       "      id: \u001b[32m\"text-embedding-3-small\"\u001b[39m,\n",
       "      object: \u001b[32m\"model\"\u001b[39m,\n",
       "      created: \u001b[33m1626777600\u001b[39m,\n",
       "      owned_by: \u001b[32m\"openai\"\u001b[39m,\n",
       "      permission: [\n",
       "        {\n",
       "          id: \u001b[32m\"modelperm-LwHkVFn8AcMItP432fKKDIKJ\"\u001b[39m,\n",
       "          object: \u001b[32m\"model_permission\"\u001b[39m,\n",
       "          created: \u001b[33m1626777600\u001b[39m,\n",
       "          allow_create_engine: \u001b[33mtrue\u001b[39m,\n",
       "          allow_sampling: \u001b[33mtrue\u001b[39m,\n",
       "          allow_logprobs: \u001b[33mtrue\u001b[39m,\n",
       "          allow_search_indices: \u001b[33mfalse\u001b[39m,\n",
       "          allow_view: \u001b[33mtrue\u001b[39m,\n",
       "          allow_fine_tuning: \u001b[33mfalse\u001b[39m,\n",
       "          organization: \u001b[32m\"*\"\u001b[39m,\n",
       "          group: \u001b[1mnull\u001b[22m,\n",
       "          is_blocking: \u001b[33mfalse\u001b[39m\n",
       "        }\n",
       "      ],\n",
       "      root: \u001b[32m\"text-embedding-3-small\"\u001b[39m,\n",
       "      parent: \u001b[1mnull\u001b[22m\n",
       "    },\n",
       "    {\n",
       "      id: \u001b[32m\"gpt-4o-mini\"\u001b[39m,\n",
       "      object: \u001b[32m\"model\"\u001b[39m,\n",
       "      created: \u001b[33m1626777600\u001b[39m,\n",
       "      owned_by: \u001b[32m\"openai\"\u001b[39m,\n",
       "      permission: [\n",
       "        {\n",
       "          id: \u001b[32m\"modelperm-LwHkVFn8AcMItP432fKKDIKJ\"\u001b[39m,\n",
       "          object: \u001b[32m\"model_permission\"\u001b[39m,\n",
       "          created: \u001b[33m1626777600\u001b[39m,\n",
       "          allow_create_engine: \u001b[33mtrue\u001b[39m,\n",
       "          allow_sampling: \u001b[33mtrue\u001b[39m,\n",
       "          allow_logprobs: \u001b[33mtrue\u001b[39m,\n",
       "          allow_search_indices: \u001b[33mfalse\u001b[39m,\n",
       "          allow_view: \u001b[33mtrue\u001b[39m,\n",
       "          allow_fine_tuning: \u001b[33mfalse\u001b[39m,\n",
       "          organization: \u001b[32m\"*\"\u001b[39m,\n",
       "          group: \u001b[1mnull\u001b[22m,\n",
       "          is_blocking: \u001b[33mfalse\u001b[39m\n",
       "        }\n",
       "      ],\n",
       "      root: \u001b[32m\"gpt-4o-mini\"\u001b[39m,\n",
       "      parent: \u001b[1mnull\u001b[22m\n",
       "    }\n",
       "  ],\n",
       "  object: \u001b[90mundefined\u001b[39m\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2025e08-7565-4c49-a639-8cb3a4091eab",
   "metadata": {},
   "source": [
    "# 使用 langchain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5059b3a7-ade8-4fe7-b904-c0de4c945784",
   "metadata": {},
   "source": [
    "作为一个框架，LangChain 提供了一个抽象层，可以让我们更容易地使用各种 LLM（大语言模型）服务，包括但不限于 OpenAI 及其他 API 服务。LangChain 封装了底层 API 调用，提供了更高级的功能，如：链式调用（Chains）、记忆管理（Memory）、代理（Agents）、文档处理、提示词管理等\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b6fdef-da1d-4ba0-9d4f-f31765af39a0",
   "metadata": {},
   "source": [
    "在项目代码文件中，Deno 可能会提示包不存在，这是我们需要执行`deno add npm:openai`来下载对应的包（其实是修改了 deno.json 文件，Deno 也会在运行时自动解析和抓取所需的模块）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0fafe46-89b4-42f6-b298-4e3b79455a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "// 初始化 LangChain 的 ChatOpenAI\n",
    "const chatModel = new ChatOpenAI({\n",
    "  configuration: {\n",
    "    baseURL: \"https://yunwu.ai/v1\",\n",
    "  },\n",
    "  modelName: \"gpt-4o-mini\", // 使用可用的模型\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc8080-e611-4f9b-a0e6-59a70ca35874",
   "metadata": {},
   "source": [
    "你可能会注意到这里并未显式给出 API-key，这是因为 Langchain 支持读取系统环境？？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7b8a256-6487-45ca-946e-29df07fce390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始对话测试...\n",
      "AI 回复: 你好！我是一个人工智能助手，旨在提供信息和帮助解决问题。我可以回答各种问题、提供建议、帮助学习新知识，或者与您进行有趣的对话。如果您有任何特定的问题或主题，欢迎随时告诉我！\n"
     ]
    }
   ],
   "source": [
    "// 使用 LangChain 进行对话测试\n",
    "console.log(\"\\n开始对话测试...\")\n",
    "const response = await chatModel.invoke([\n",
    "  new HumanMessage(\"你好！请介绍一下你自己。\"),\n",
    "])\n",
    "\n",
    "console.log(\"AI 回复:\", response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366722a-3cd2-44ec-ba2a-697666ec3ed9",
   "metadata": {},
   "source": [
    "成功！\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
